model_name: "Qwen/Qwen2.5-1.5B-Instruct"
math_variant: true
output_dir: "outputs"
seed: 42

# Data / lengths
max_prompt_len: 1024
max_new_tokens: 1024

# GRPO
group_size: 4
beta: 0.1
cliphigher: 5.0
adv_norm_eps: 1e-8

# Overlong / masks
overlong_penalty: -0.2
length_penalty_alpha: 0.0
eos_token: "<|endoftext|>"

# Dynamic Scaled Gradient
dsd_tau: 0.95
dsd_min: 0.5
dsd_max: 2.0

# QLoRA
lora_r: 64
lora_alpha: 128
lora_dropout: 0.05
bnb_4bit: true
bnb_4bit_compute_dtype: "bfloat16"

# Optim & schedule
lr: 1.5e-5
warmup_steps: 50
weight_decay: 0.0
bf16: true
gradient_accumulation_steps: 4
per_device_train_batch_size: 1
max_steps: 1500
eval_every: 200
save_every: 200
log_every: 10
